import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'scripts'))

import pandas as pd
import streamlit as st
from enhanced_data_processor import EnhancedTikTokDataProcessor

st.title("ğŸ”§ ç›´æ¥æµ‹è¯• merge_data")

st.write("### ğŸ“‹ åŸºæœ¬ä¿¡æ¯")
st.write(f"Python ç‰ˆæœ¬: {sys.version}")
st.write(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")

# åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
st.write("### ğŸ”§ åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨")
try:
    processor = EnhancedTikTokDataProcessor()
    st.success("âœ… æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # æ£€æŸ¥æ•°æ®
    st.write("### ğŸ“Š æ•°æ®æ£€æŸ¥")
    st.write(f"redash_df: {processor.redash_df.shape if processor.redash_df is not None else 'None'}")
    st.write(f"accounts_df: {processor.accounts_df.shape if processor.accounts_df is not None else 'None'}")
    st.write(f"clicks_df: {processor.clicks_df.shape if processor.clicks_df is not None else 'None'}")
    
    # ç›´æ¥æµ‹è¯• merge_data çš„é€»è¾‘
    st.write("### ğŸ”„ ç›´æ¥æµ‹è¯• merge_data é€»è¾‘")
    
    # è·å–æ•°æ®
    redash_df = processor.redash_df
    accounts_df = processor.accounts_df
    clicks_df = processor.clicks_df
    
    st.write(f"[DEBUG] redash_df shape: {redash_df.shape if redash_df is not None else 'None'}")
    st.write(f"[DEBUG] accounts_df shape: {accounts_df.shape if accounts_df is not None else 'None'}")
    st.write(f"[DEBUG] clicks_df shape: {clicks_df.shape if clicks_df is not None else 'None'}")
    
    if redash_df is None:
        st.error("âŒ redash_df ä¸º None")
        st.stop()
    
    if accounts_df is None:
        st.error("âŒ accounts_df ä¸º None")
        st.stop()
    
    # åˆ›å»º group_mapping
    st.write("[DEBUG] åˆ›å»º group_mapping...")
    try:
        if 'Tiktok ID' not in accounts_df.columns or 'Groups' not in accounts_df.columns:
            st.error(f"âŒ accounts_df ç¼ºå°‘å¿…è¦çš„åˆ—ï¼Œå®é™…åˆ—: {accounts_df.columns.tolist()}")
            st.stop()
        
        accounts_df['Tiktok ID'] = accounts_df['Tiktok ID'].astype(str)
        group_mapping = accounts_df[['Tiktok ID', 'Groups']].drop_duplicates()
        group_mapping = group_mapping.rename(columns={'Tiktok ID': 'user_id', 'Groups': 'group'})
        group_mapping['user_id'] = group_mapping['user_id'].astype(str)
        group_mapping['group'] = group_mapping['group'].fillna('Unknown')
        
        st.write(f"[DEBUG] group_mapping shape: {group_mapping.shape}")
        st.write(f"[DEBUG] group_mapping columns: {group_mapping.columns.tolist()}")
        
    except Exception as e:
        st.error(f"âŒ åˆ›å»º group_mapping å¤±è´¥: {str(e)}")
        st.stop()
    
    # å¤„ç† redash_df çš„æ—¥æœŸåˆ—
    st.write("[DEBUG] å¤„ç† redash_df æ—¥æœŸåˆ—...")
    try:
        if 'date' not in redash_df.columns:
            if 'YMDdate' in redash_df.columns:
                redash_df['date'] = pd.to_datetime(redash_df['YMDdate'], errors='coerce')
                st.write("[DEBUG] ä» 'YMDdate' åˆ—åˆ›å»º 'date' åˆ—")
            else:
                st.error(f"âŒ redash_df ç¼ºå°‘æ—¥æœŸåˆ—ï¼Œå®é™…åˆ—: {redash_df.columns.tolist()}")
                st.stop()
        
        if not pd.api.types.is_datetime64_any_dtype(redash_df['date']):
            redash_df['date'] = pd.to_datetime(redash_df['date'], errors='coerce')
        
        redash_df = redash_df.dropna(subset=['date'])
        st.write(f"[DEBUG] å¤„ç†æ—¥æœŸå redash_df shape: {redash_df.shape}")
        
    except Exception as e:
        st.error(f"âŒ å¤„ç†æ—¥æœŸåˆ—å¤±è´¥: {str(e)}")
        st.stop()
    
    # å¤„ç† user_id åˆ—
    st.write("[DEBUG] å¤„ç† user_id åˆ—...")
    try:
        if 'user_id' in redash_df.columns:
            redash_df['user_id'] = redash_df['user_id'].astype(str)
            st.write(f"[DEBUG] redash_df['user_id'] dtype: {redash_df['user_id'].dtype}")
        else:
            st.error(f"âŒ redash_df ç¼ºå°‘ 'user_id' åˆ—ï¼Œå®é™…åˆ—: {redash_df.columns.tolist()}")
            st.stop()
    except Exception as e:
        st.error(f"âŒ å¤„ç† user_id åˆ—å¤±è´¥: {str(e)}")
        st.stop()
    
    # æ‰§è¡Œåˆå¹¶
    st.write("[DEBUG] æ‰§è¡Œåˆå¹¶æ“ä½œ...")
    try:
        st.write(f"[DEBUG] redash_df shape: {redash_df.shape}")
        st.write(f"[DEBUG] group_mapping shape: {group_mapping.shape}")
        st.write(f"[DEBUG] redash_df columns: {redash_df.columns.tolist()}")
        st.write(f"[DEBUG] group_mapping columns: {group_mapping.columns.tolist()}")
        
        merged_df = redash_df.merge(group_mapping, on='user_id', how='left')
        
        st.write(f"[DEBUG] åˆå¹¶å shape: {merged_df.shape}")
        st.write(f"[DEBUG] merged_df columns: {merged_df.columns.tolist()}")
        
        # å¤„ç† group åˆ—
        if 'Groups' in merged_df.columns:
            merged_df = merged_df.rename(columns={'Groups': 'group'})
        merged_df['group'] = merged_df['group'].fillna('Unknown')
        
        st.success("âœ… åˆå¹¶æˆåŠŸ")
        st.write("merged_df å‰3è¡Œ:")
        st.dataframe(merged_df.head(3))
        
        # è®¾ç½®ç»“æœ
        processor.merged_df = merged_df
        processor.group_mapping = group_mapping
        processor.clicks_df = clicks_df
        
        st.success("âœ… æ•°æ®å¤„ç†å™¨æ›´æ–°æˆåŠŸ")
        
    except Exception as e:
        st.error(f"âŒ åˆå¹¶æ“ä½œå¤±è´¥: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        st.stop()
        
except Exception as e:
    st.error(f"âŒ é”™è¯¯: {str(e)}")
    import traceback
    st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}") 